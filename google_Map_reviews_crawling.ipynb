{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1F3XcvMx75G",
        "outputId": "c128d2af-80f1-4e0d-f907-166f79693212"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (4.16.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from selenium) (1.26.16)\n",
            "Requirement already satisfied: trio~=0.17 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from selenium) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
            "Requirement already satisfied: sortedcontainers in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
            "Requirement already satisfied: outcome in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
            "Requirement already satisfied: cffi>=1.14 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jeonghwan cho\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NkUoPPlyx75K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlVI0DY1x75K"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "# selenium key control\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "# for page loading\n",
        "import time\n",
        "\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "\n",
        "# chrome driver\n",
        "driver = webdriver.Chrome()\n",
        "\n",
        "# url in chrome driver\n",
        "driver.get('https://www.google.com/maps/?entry=ttu')\n",
        "\n",
        "# wait 3 secs for driver to load\n",
        "time.sleep(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fSQvmMdlx75L"
      },
      "outputs": [],
      "source": [
        "# change the station file when you work\n",
        "file_name = 'asakusaline.csv'\n",
        "line_name = file_name[:-4]\n",
        "\n",
        "station_file = pd.read_csv('data/metro_data/'+file_name)\n",
        "station_list = station_file['statnNm']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6tJBGaOx75L",
        "outputId": "779b373d-a161-46f0-ff5e-e8b435fbaae4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0              Sengakuji\n",
              "1                   Mita\n",
              "2                 Daimon\n",
              "3              Shimbashi\n",
              "4          Higashi-ginza\n",
              "5              Takaracho\n",
              "6             Nihombashi\n",
              "7              Ningyocho\n",
              "8     Higashi-nihombashi\n",
              "9           Asakusabashi\n",
              "10               Kuramae\n",
              "11               Asakusa\n",
              "12      Honjo-azumabashi\n",
              "13               Oshiage\n",
              "Name: statnNm, dtype: object"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "station_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DZVQLrYx75M"
      },
      "outputs": [],
      "source": [
        "crawling_data = pd.DataFrame(columns = ['statnNm', 'rating', 'review']) #string, float, list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isxw08b5x75N",
        "outputId": "330da35f-66d4-43a6-d3c6-9ac23f809625"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
            "C:\\Users\\Jeonghwan Cho\\AppData\\Local\\Temp\\ipykernel_11656\\2464430071.py:42: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  crawling_data = crawling_data.append(add_row, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "search = driver.find_element(By.CLASS_NAME, 'searchboxinput.xiQnY')\n",
        "\n",
        "search.clear()\n",
        "\n",
        "for stat in station_list:\n",
        "    station = stat + ' station'\n",
        "    search.send_keys(station)\n",
        "    search.send_keys(Keys.RETURN)\n",
        "    time.sleep(1)\n",
        "\n",
        "    count = input('몇 개?') #search result: 1 / 2, if no ratings 0\n",
        "\n",
        "    for i in range(int(count)):\n",
        "        # ratings\n",
        "        stop = input('y/n') # click another station\n",
        "\n",
        "        try:\n",
        "            rating = float(driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[2]/div[2]/div/div[1]/div[2]/div/div[1]/div[2]/span[1]/span[1]').text)\n",
        "\n",
        "        except:\n",
        "            rating = float(driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div/div[1]/div[2]/div/div[1]/div[2]/span[1]/span[1]').text)\n",
        "\n",
        "        # click the review button\n",
        "        try:\n",
        "            review_butt = driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[2]/div[3]/div/div/button[2]/div[2]/div[2]')\n",
        "            review_butt.click()\n",
        "            ch = input('y/n') # check whether it is scrolled down fully\n",
        "            reviews = driver.find_elements(By.CLASS_NAME, 'MyEned')\n",
        "\n",
        "            review = []\n",
        "\n",
        "            for i in reviews:\n",
        "                review.append(i.text)\n",
        "\n",
        "            add_row = {'statnNm': stat, 'rating': rating, 'review':review}\n",
        "            crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
        "\n",
        "        except:\n",
        "            add_row = {'statnNm': stat, 'rating': rating, 'review':''}\n",
        "            crawling_data = crawling_data.append(add_row, ignore_index=True)\n",
        "\n",
        "    #스크롤\n",
        "    '''\n",
        "    for i in range(10):\n",
        "        driver.find_element(By.XPATH, '//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[3]').send_keys(Keys.PAGE_DOWN)\n",
        "\n",
        "    '''\n",
        "\n",
        "    search.clear()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teOEtp2Fx75O"
      },
      "outputs": [],
      "source": [
        "crawling_data.to_csv('data/kr_review/'+line_name+'_review.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
